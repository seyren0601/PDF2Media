{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_label(line):\n",
    "    fields = line.split('\\t')\n",
    "    notes = [note for note in fields if 'note' in note] \n",
    "    notes_processed = []\n",
    "    for note in notes:\n",
    "        # ignore rests and gracenotes\n",
    "        if 'gracenote' in note:\n",
    "            pass\n",
    "        else:\n",
    "            # search for sharps and flats\n",
    "            # redundant because we will try to recognize the clef key\n",
    "            match = re.search(r'[A-Z][b#][0-9]', note)\n",
    "            if match is not None:\n",
    "                index = match.start()\n",
    "                note = note[:index + 1] + note[index + 2:]\n",
    "            notes_processed.append(note)\n",
    "    return notes_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\primus\\\\data\\\\data.semantic'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m folder_name \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(data_dir_path):\n\u001b[1;32m---> 11\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_dir_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfolder_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfolder_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.semantic\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m semantic_file:\n\u001b[0;32m     12\u001b[0m         content \u001b[38;5;241m=\u001b[39m semantic_file\u001b[38;5;241m.\u001b[39mreadline()\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;66;03m# only take samples in G clef\u001b[39;00m\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;66;03m# and contains 1 clef only\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\primus\\\\data\\\\data.semantic'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import shutil\n",
    "\n",
    "data_dir_path = 'D:\\\\primus'\n",
    "labels = []\n",
    "\n",
    "index=0\n",
    "for folder_name in os.listdir(data_dir_path):\n",
    "    with open(data_dir_path + \"\\\\\" + folder_name + f\"\\\\{folder_name}.semantic\") as semantic_file:\n",
    "        content = semantic_file.readline()\n",
    "        # only take samples in G2 clef\n",
    "        # and contains 1 clef only\n",
    "        if 'clef-G2' in content and content.count('clef') == 1:\n",
    "            labels.append(get_label(content))\n",
    "            shutil.copy(data_dir_path + \"\\\\\" + folder_name + f\"\\\\{folder_name}.png\",\n",
    "                        f\"d:\\\\\\primus_cleaned_data\\\\{index}.png\")\n",
    "            index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48040\n"
     ]
    }
   ],
   "source": [
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['note-F4_eighth', 'note-B4_half.', 'note-E5_eighth', 'note-D5_eighth', 'note-D5_half.', 'note-G5_eighth', 'note-F5_eighth', 'note-F5_quarter', 'rest-sixteenth', 'note-F5_sixteenth', 'note-G5_sixteenth', 'note-A5_sixteenth', 'note-B5_sixteenth', 'note-F5_sixteenth', 'note-F5_sixteenth', 'note-F5_sixteenth', 'note-C6_sixteenth', 'note-F5_sixteenth', 'note-F5_sixteenth', 'note-F5_sixteenth']\n"
     ]
    }
   ],
   "source": [
    "print(labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save list of labels to json\n",
    "import json\n",
    "\n",
    "with open('dataset\\\\labels.json', 'w') as f:\n",
    "    json.dump(labels, f, indent=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load list of labels from json\n",
    "with open('dataset\\\\labels.json', 'r') as f:\n",
    "    labels_loaded = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48040\n"
     ]
    }
   ],
   "source": [
    "print(len(labels_loaded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the template matching method of OpenCV and Tesseract\n",
    "# to identify notes and box them\n",
    "import os\n",
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = 'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe'\n",
    "\n",
    "def find_best_coeff(template, img2, res_max_global, increasing=True, decreasing=True, time=False):\n",
    "    max_matches = 0\n",
    "    best_coeff = 1\n",
    "    template_copy = template\n",
    "\n",
    "    ###################Decreasing:\n",
    "    if decreasing:\n",
    "        for i in range(3):\n",
    "            template = template_copy\n",
    "            img = img2.copy()\n",
    "            # Scaling coeff in range [0.2, 1] with step = 0.1\n",
    "            coeff = 1 - i/10.0\n",
    "            template = cv2.resize(template, (0,0), fx=coeff, fy=coeff)\n",
    "            w, h = template.shape[::-1]\n",
    "\n",
    "            try:\n",
    "                res = cv2.matchTemplate(img, template, cv2.TM_CCOEFF_NORMED)\n",
    "            except:\n",
    "                continue\n",
    "            res_max = res.max()\n",
    "\n",
    "            threshold = res_max_global\n",
    "            loc = np.where(res >= threshold)\n",
    "            indices = set()\n",
    "            for pt in zip(*loc[::-1]):\n",
    "                x = int(pt[0] + w/2)\n",
    "                upper_bound = x + 30\n",
    "                lower_bound = x - 30\n",
    "                found = False\n",
    "                for i in range(lower_bound, upper_bound):\n",
    "                    if i in indices: \n",
    "                        found = True\n",
    "                        break\n",
    "                if not found:\n",
    "                    indices.add(x)\n",
    "            if time:\n",
    "                if res_max >= res_max_global:\n",
    "                    res_max_global = res_max\n",
    "                    best_coeff = coeff\n",
    "            elif len(indices) > max_matches and res_max >= res_max_global:\n",
    "                max_matches = len(indices)\n",
    "                res_max_global = res_max\n",
    "                best_coeff = coeff\n",
    "                \n",
    "\n",
    "    ###################Increasing:\n",
    "    if increasing:\n",
    "        for i in range(3):\n",
    "            template = template_copy\n",
    "            img = img2.copy()\n",
    "            # Scaling coeff in range [1, 1.8] with step = 0.1\n",
    "            coeff = 1 + i/10.0\n",
    "            template = cv2.resize(template, (0,0), fx=coeff, fy=coeff)\n",
    "            w, h = template.shape[::-1]\n",
    "            if(template.shape[0] > img.shape[0]): break\n",
    "\n",
    "            res = cv2.matchTemplate(img, template, cv2.TM_CCOEFF_NORMED)\n",
    "            res_max = res.max()\n",
    "\n",
    "            threshold = res_max_global\n",
    "            loc = np.where(res >= threshold)\n",
    "            indices = set()\n",
    "            for pt in zip(*loc[::-1]):\n",
    "                x = int(pt[0] + w/2)\n",
    "                upper_bound = x + 30\n",
    "                lower_bound = x - 30\n",
    "                found = False\n",
    "                for i in range(lower_bound, upper_bound):\n",
    "                    if(i in indices): \n",
    "                        found = True\n",
    "                        break\n",
    "                if not found:\n",
    "                    indices.add(x)\n",
    "            if len(indices) > max_matches and res_max >= res_max_global:\n",
    "                max_matches = len(indices)\n",
    "                res_max_global = res_max\n",
    "                best_coeff = coeff\n",
    "\n",
    "    return(res_max_global, best_coeff)\n",
    "\n",
    "def staff_to_boxed_notes(file):\n",
    "    img = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
    "    indices = set()\n",
    "    \n",
    "    drawn_indices = set()\n",
    "    list_pt = {}\n",
    "    boxes = []\n",
    "    # start_index = 0\n",
    "    # time_indices = set()\n",
    "    # best_res = 0\n",
    "    \n",
    "    # # detect time signature, then crop the staff\n",
    "    # # to start from there\n",
    "    # for dir in os.listdir('template\\\\time'):\n",
    "    #     template = cv2.imread(f'template\\\\time\\\\{dir}', cv2.IMREAD_GRAYSCALE)\n",
    "    #     template = cv2.resize(template,(0,0),fx=img.shape[0]/template.shape[0],fy=img.shape[0]/template.shape[0])\n",
    "    #     template_copy = template.copy()\n",
    "        \n",
    "    #     res_max, coeff = find_best_coeff(template_copy, img, 0.7, increasing=False, time=True)\n",
    "        \n",
    "    #     template = cv2.resize(template,(0,0),fx=coeff,fy=coeff) #scale the template to the best coeff\n",
    "\n",
    "    #     w, h = template.shape[::-1] # Get w and h of template\n",
    "    #     res = cv2.matchTemplate(img, template, cv2.TM_CCOEFF_NORMED) # Begin matching and get matches\n",
    "    #     if res_max > best_res:\n",
    "    #         best_res = res_max\n",
    "    #         best_template = template\n",
    "    # threshold = best_res\n",
    "    # template = best_template\n",
    "    # res = cv2.matchTemplate(img, template, cv2.TM_CCOEFF_NORMED) # Begin matching and get matches\n",
    "    # loc = np.where(res >= threshold) # With threshold to offset the difference between template and notes (with staff)\n",
    "    \n",
    "    # for pt in zip(*loc[::-1]):\n",
    "    #     x = int(pt[0] + w/2)\n",
    "    #     upper_bound = x + 10\n",
    "    #     lower_bound = x - 10\n",
    "    #     found = False\n",
    "    #     for i in range(lower_bound, upper_bound):\n",
    "    #         if(i in indices):\n",
    "    #             found = True\n",
    "    #             break\n",
    "    #     if not found:\n",
    "    #         list_pt[x] = pt\n",
    "    #         time_indices.add(x)\n",
    "    # if len(time_indices) > 0:\n",
    "    #     for x in time_indices:\n",
    "    #         pt = list_pt[x]\n",
    "    #         start_index = pt[0]\n",
    "    # img = img[0:img.shape[0],start_index + best_template.shape[1]:start_index + img.shape[1]]\n",
    "    # list_pt = {}\n",
    "    \n",
    "    # cv2.imwrite(\"cropped.jpg\", img)\n",
    "\n",
    "    for dir in os.listdir('template\\\\roots'):\n",
    "        # The template to be matched\n",
    "        template = cv2.imread(f'template\\\\roots\\\\{dir}', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        res_max, coeff = find_best_coeff(template, img, 0.8)\n",
    "        template = cv2.resize(template,(0,0),fx=coeff,fy=coeff) #scale the tepmplate to the best coeff\n",
    "\n",
    "        w, h = template.shape[::-1] # Get w and h of template\n",
    "\n",
    "        try:\n",
    "            res = cv2.matchTemplate(img, template, cv2.TM_CCOEFF_NORMED) # Begin matching and get matches\n",
    "        except:\n",
    "            continue\n",
    "        if 'half-note' in dir or 'whole-note' in dir:\n",
    "            threshold = res_max * 0.7\n",
    "        else:\n",
    "            threshold = res_max * 0.7\n",
    "        loc = np.where(res >= threshold) # With threshold to offset the difference between template and notes (with staff)\n",
    "\n",
    "        # Get a set of center indices of boxes for further testing\n",
    "        \n",
    "        for pt in zip(*loc[::-1]):\n",
    "            x = int(pt[0] + w/2)\n",
    "            upper_bound = x + 10\n",
    "            lower_bound = x - 10\n",
    "            found = False\n",
    "            for i in range(lower_bound, upper_bound):\n",
    "                if(i in indices):\n",
    "                    found = True\n",
    "                    break\n",
    "            if not found:\n",
    "                list_pt[x] = pt\n",
    "                indices.add(x)\n",
    "        for x in indices:\n",
    "            pt = list_pt[x]\n",
    "            # draw boxes in copy of image\n",
    "            if x not in drawn_indices:\n",
    "                boxes.append((x, cv2.resize(img[0:img.shape[0], pt[0] - int(w * 0.5):pt[0] + int(w * 1.5)], (49, 149))))\n",
    "                # cv2.rectangle(img, (pt[0], 0), (pt[0] + int(w * 1.4), img.shape[0]), (0,0,255), 2)\n",
    "                drawn_indices.add(x)\n",
    "        # cv2.imwrite('boxed.jpg', img)\n",
    "    boxes.sort(key=lambda x:x[0])\n",
    "    boxes = [i[1] for i in boxes]\n",
    "    return boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "(149, 40)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = \"d:\\\\primus_cleaned_data\\\\7.png\"\n",
    "notes_found = staff_to_boxed_notes(file)\n",
    "print(len(notes_found))\n",
    "print(notes_found[0].shape)\n",
    "cv2.imwrite('box.jpg', notes_found[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "17\n",
      "['note-F5_half.', 'note-E5_eighth', 'note-D5_eighth', 'note-D5_half.', 'note-C5_eighth', 'note-B4_eighth', 'note-B4_half', 'note-B4_eighth', 'note-C5_eighth', 'note-C5_eighth', 'note-B4_eighth', 'note-A4_eighth', 'note-B4_eighth', 'gracenote-A4_eighth', 'note-G4_quarter', 'note-F4_quarter', 'rest-half']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "test_index = 30\n",
    "# load list of labelsfrom json\n",
    "with open('dataset\\\\labels.json', 'r') as f:\n",
    "    labels_loaded = json.load(f)\n",
    "    \n",
    "notes_count = sum(1 for token in labels_loaded[test_index] if 'note' in token and 'gracenote' not in token)\n",
    "print(notes_count)\n",
    "print(len(labels_loaded[test_index]))\n",
    "print(labels_loaded[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeee665eb71e468ca2864f9800c68da8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/48040 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correctly identified: 12137\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(num)):\n\u001b[1;32m---> 26\u001b[0m     count \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mcheck_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorrectly identified: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcount\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[45], line 16\u001b[0m, in \u001b[0;36mcheck_samples\u001b[1;34m(i)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_samples\u001b[39m(i):\n\u001b[0;32m     15\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mprimus_cleaned_data\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 16\u001b[0m     found_notes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mstaff_to_boxed_notes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     17\u001b[0m     notes_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(labels_loaded[i])\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchecked \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png \u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\r\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[44], line 160\u001b[0m, in \u001b[0;36mstaff_to_boxed_notes\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    159\u001b[0m     threshold \u001b[38;5;241m=\u001b[39m res_max \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.7\u001b[39m\n\u001b[1;32m--> 160\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# With threshold to offset the difference between template and notes (with staff)\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;66;03m# Get a set of center indices of boxes for further testing\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m pt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mloc[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]):\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mwhere\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "import joblib\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# load list of labelsfrom json\n",
    "with open('dataset\\\\labels.json', 'r') as f:\n",
    "    labels_loaded = json.load(f)\n",
    "    \n",
    "num = len(labels_loaded)\n",
    "count = 0\n",
    "correct_samples = []\n",
    "\n",
    "def check_samples(i):\n",
    "    file = f\"d:\\\\primus_cleaned_data\\\\{i}.png\"\n",
    "    found_notes = list(staff_to_boxed_notes(file))\n",
    "    notes_count = len(labels_loaded[i])\n",
    "    print(f\"checked {i}.png \", end='\\r')\n",
    "    if notes_count == len(found_notes):\n",
    "        correct_samples.append(i)\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "for i in tqdm(range(num)):\n",
    "    count += check_samples(i)\n",
    "    print(f\"correctly identified: {count}\", end=\"\\r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save list of correct samples' indices to json\n",
    "import json\n",
    "\n",
    "with open('dataset\\\\matched_samples.json', 'w') as f:\n",
    "    json.dump(correct_samples, f, indent=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a0e4d2f920143b486874f94e46ba014",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41495 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracted notes in 48039.jpg\r"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "test_index = 30\n",
    "# load list of labelsfrom json\n",
    "with open('dataset\\\\matched_samples.json', 'r') as f:\n",
    "    matched_samples = json.load(f)\n",
    "    \n",
    "for i in tqdm(matched_samples):\n",
    "    boxes = staff_to_boxed_notes(f'D:\\\\primus_cleaned_data\\\\{i}.png')\n",
    "    count = 0\n",
    "    for box in boxes:\n",
    "        cv2.imwrite(f\"D:\\\\primus_notes\\\\{i}_{count}.jpg\", box)\n",
    "        count += 1\n",
    "    print(f\"extracted notes in {i}.jpg\", end='\\r')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
